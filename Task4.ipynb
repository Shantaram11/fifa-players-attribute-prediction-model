{"cells":[{"cell_type":"code","execution_count":1,"id":"12e631e2-8271-4900-828e-893a9d1402de","metadata":{},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark import SparkContext, SQLContext\n","from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n","from datetime import datetime"]},{"cell_type":"code","execution_count":2,"id":"3fa74703","metadata":{},"outputs":[],"source":["import warnings\n","\n","# Suppress all warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"07c350b6-a27e-4887-854e-91614554eaa3","metadata":{},"source":["Task 1"]},{"cell_type":"code","execution_count":5,"id":"b07d29e9-48e9-45b7-9e93-3b9ad30e51f5","metadata":{},"outputs":[],"source":["spark = SparkSession.builder \\\n","    .master(\"yarn\") \\\n","    .appName(\"SystemsToolChains\") \\\n","    .getOrCreate()\n","spark.sparkContext.setLogLevel(\"ERROR\")"]},{"cell_type":"code","execution_count":6,"id":"19f49d69","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# read data from csv files\n","from pyspark.sql.functions import lit, monotonically_increasing_id\n","df_list = list()\n","## read in all data for male players\n","for i in range(15, 23):\n","    file_name = \"gs://data_players/data/players_\" + str(i) + \".csv\"\n","    df = spark.read.csv(file_name, header=True, inferSchema=True)\n","    year = 2000 + i\n","    gender = \"Male\"\n","    df = df.withColumn(\"year\", lit(year))\n","    df = df.withColumn(\"gender\", lit(gender))\n","    df_list.append(df)\n","    \n","## merge all data into one dataframe\n","df_merged = df_list[0]\n","for df in df_list[1:]:\n","    df_merged = df_merged.union(df)\n","    \n","## create new column to storage unique id for each piece of data \n","df_merged = df_merged.withColumn(\"record_id\", monotonically_increasing_id())"]},{"cell_type":"code","execution_count":7,"id":"899f4665","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/11/13 03:24:09 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["-RECORD 0-------------------------------------------\n"," sofifa_id                   | 158023               \n"," player_url                  | https://sofifa.co... \n"," short_name                  | L. Messi             \n"," long_name                   | Lionel Andrés Mes... \n"," player_positions            | CF                   \n"," overall                     | 93                   \n"," potential                   | 95                   \n"," value_eur                   | 1.005E8              \n"," wage_eur                    | 550000.0             \n"," age                         | 27                   \n"," dob                         | 1987-06-24           \n"," height_cm                   | 169                  \n"," weight_kg                   | 67                   \n"," club_team_id                | 241.0                \n"," club_name                   | FC Barcelona         \n"," league_name                 | Spain Primera Div... \n"," league_level                | 1                    \n"," club_position               | CF                   \n"," club_jersey_number          | 10                   \n"," club_loaned_from            | NULL                 \n"," club_joined                 | 2004-07-01           \n"," club_contract_valid_until   | 2018                 \n"," nationality_id              | 52                   \n"," nationality_name            | Argentina            \n"," nation_team_id              | 1369.0               \n"," nation_position             | CF                   \n"," nation_jersey_number        | 10                   \n"," preferred_foot              | Left                 \n"," weak_foot                   | 3                    \n"," skill_moves                 | 4                    \n"," international_reputation    | 5                    \n"," work_rate                   | Medium/Low           \n"," body_type                   | Normal (170-)        \n"," real_face                   | Yes                  \n"," release_clause_eur          | NULL                 \n"," player_tags                 | #Speedster, #Drib... \n"," player_traits               | Finesse Shot, Spe... \n"," pace                        | 93                   \n"," shooting                    | 89                   \n"," passing                     | 86                   \n"," dribbling                   | 96                   \n"," defending                   | 27                   \n"," physic                      | 63                   \n"," attacking_crossing          | 84                   \n"," attacking_finishing         | 94                   \n"," attacking_heading_accuracy  | 71                   \n"," attacking_short_passing     | 89                   \n"," attacking_volleys           | 85                   \n"," skill_dribbling             | 96                   \n"," skill_curve                 | 89                   \n"," skill_fk_accuracy           | 90                   \n"," skill_long_passing          | 76                   \n"," skill_ball_control          | 96                   \n"," movement_acceleration       | 96                   \n"," movement_sprint_speed       | 90                   \n"," movement_agility            | 94                   \n"," movement_reactions          | 94                   \n"," movement_balance            | 95                   \n"," power_shot_power            | 80                   \n"," power_jumping               | 73                   \n"," power_stamina               | 77                   \n"," power_strength              | 60                   \n"," power_long_shots            | 88                   \n"," mentality_aggression        | 48                   \n"," mentality_interceptions     | 22                   \n"," mentality_positioning       | 92                   \n"," mentality_vision            | 90                   \n"," mentality_penalties         | 76                   \n"," mentality_composure         | NULL                 \n"," defending_marking_awareness | 25                   \n"," defending_standing_tackle   | 21                   \n"," defending_sliding_tackle    | 20                   \n"," goalkeeping_diving          | 6                    \n"," goalkeeping_handling        | 11                   \n"," goalkeeping_kicking         | 15                   \n"," goalkeeping_positioning     | 14                   \n"," goalkeeping_reflexes        | 8                    \n"," goalkeeping_speed           | NULL                 \n"," ls                          | 89+3                 \n"," st                          | 89+3                 \n"," rs                          | 89+3                 \n"," lw                          | 92+3                 \n"," lf                          | 90+3                 \n"," cf                          | 90+3                 \n"," rf                          | 90+3                 \n"," rw                          | 92+3                 \n"," lam                         | 92+3                 \n"," cam                         | 92+3                 \n"," ram                         | 92+3                 \n"," lm                          | 90+3                 \n"," lcm                         | 79+3                 \n"," cm                          | 79+3                 \n"," rcm                         | 79+3                 \n"," rm                          | 90+3                 \n"," lwb                         | 62+3                 \n"," ldm                         | 62+3                 \n"," cdm                         | 62+3                 \n"," rdm                         | 62+3                 \n"," rwb                         | 62+3                 \n"," lb                          | 54+3                 \n"," lcb                         | 45+3                 \n"," cb                          | 45+3                 \n"," rcb                         | 45+3                 \n"," rb                          | 54+3                 \n"," gk                          | 15+3                 \n"," player_face_url             | https://cdn.sofif... \n"," club_logo_url               | https://cdn.sofif... \n"," club_flag_url               | https://cdn.sofif... \n"," nation_logo_url             | https://cdn.sofif... \n"," nation_flag_url             | https://cdn.sofif... \n"," year                        | 2015                 \n"," gender                      | Male                 \n"," record_id                   | 0                    \n","only showing top 1 row\n","\n"]}],"source":["# an example of dataset\n","df_read = df_merged\n","df_read.show(1, vertical=True)"]},{"cell_type":"code","execution_count":8,"id":"fac6f81f-f151-4dbf-bc69-7d28729f9d3e","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import col, desc, asc\n","\n","## Task 2.1\n","def get_clubs_with_most_players(year, n_club, ending_year):\n","    df_casted = df_read.withColumn(\"club_contract_valid_until_int\", col(\"club_contract_valid_until\").cast(\"integer\"))\n","    df_filtered = df_casted.filter((df_casted.year == year) & (df_casted.club_contract_valid_until_int >= ending_year))\n","    df_grouped = df_filtered.groupBy(\"club_name\").count()\n","    df_ordered = df_grouped.orderBy(desc(\"count\"))\n","    df_limited = df_ordered.limit(n_club)\n","    print(f\"the {n_club} clubs with most players in year {year} whose contract ending in or after year {ending_year}\")\n","    df_limited.show()\n","\n","## Task 2.2 parameter order is in [\"highest\", \"lowest\"]\n","def get_clubs_with_highest_or_lowest_average_age(year, n_club, order):\n","    original_n = n_club\n","    df_filtered = df_read.filter(df_read.year == year)\n","    df_grouped = df_filtered.groupBy(\"club_name\").avg(\"age\")\n","    if order == \"lowest\":\n","        df_ordered = df_grouped.orderBy(asc(\"avg(age)\"))\n","    elif order == \"highest\":\n","        df_ordered = df_grouped.orderBy(desc(\"avg(age)\"))\n","    if n_club < df_ordered.count():\n","        while 1:\n","            if df_ordered.limit(n_club).collect()[-1][\"avg(age)\"] == df_ordered.limit(n_club+1).collect()[-1][\"avg(age)\"]:\n","                n_club += 1\n","            else:\n","                break\n","    df_limited = df_ordered.limit(n_club)\n","    print(f\"the {original_n} clubs with {order} average ages for players in year {year}\")\n","    df_limited.show()\n","\n","## Task 2.3\n","def get_most_popular_nationality(year):\n","    df_filtered = df_read.filter(df_read.year == year)\n","    df_grouped = df_filtered.groupBy(\"nationality_name\").count()\n","    df_ordered = df_grouped.orderBy(desc(\"count\"))\n","    df_limited = df_ordered.limit(1)\n","    print(f\"Most Popular Nationality in Year {year}\")\n","    df_limited.show()"]},{"cell_type":"code","execution_count":9,"id":"18569107-a1f8-4d43-b574-39a3c4cfd093","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["the 5 clubs with most players in year 2020 whose contract ending in or after year 2024\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 17:>                                                         (0 + 2) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+-----+\n","|          club_name|count|\n","+-------------------+-----+\n","|Patriotas Boyacá FC|   12|\n","|   Deportes Iquique|   12|\n","|          Al Ain FC|   11|\n","|     Atlético Huila|   11|\n","|  Alianza Petrolera|   11|\n","+-------------------+-----+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["## Test task 2.1 get_clubs_with_most_players(year, n_club, ending_year)\n","get_clubs_with_most_players(2020, 5, 2024)"]},{"cell_type":"code","execution_count":10,"id":"b18bda57-f85f-44ec-bc77-1ddf235a423f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["the 3 clubs with highest average ages for players in year 2020\n","+--------------------+--------+\n","|           club_name|avg(age)|\n","+--------------------+--------+\n","|           Fortaleza|    32.6|\n","|            Cruzeiro|    31.6|\n","|            Botafogo|    31.4|\n","|Associação Chapec...|    31.4|\n","|Club Athletico Pa...|    31.4|\n","+--------------------+--------+\n","\n"]}],"source":["## Test task 2.2 get_clubs_with_highest_or_lowest_average_age(year, n_club, order)\n","get_clubs_with_highest_or_lowest_average_age(2020, 3, \"highest\")"]},{"cell_type":"code","execution_count":11,"id":"b811733a-6c05-4b1d-9b20-bd045480c787","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Most Popular Nationality in Year 2015\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1627|\n","+----------------+-----+\n","\n","Most Popular Nationality in Year 2016\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1519|\n","+----------------+-----+\n","\n","Most Popular Nationality in Year 2017\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1627|\n","+----------------+-----+\n","\n","Most Popular Nationality in Year 2018\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1633|\n","+----------------+-----+\n","\n","Most Popular Nationality in Year 2019\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1625|\n","+----------------+-----+\n","\n","Most Popular Nationality in Year 2020\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1670|\n","+----------------+-----+\n","\n","Most Popular Nationality in Year 2021\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1685|\n","+----------------+-----+\n","\n","Most Popular Nationality in Year 2022\n","+----------------+-----+\n","|nationality_name|count|\n","+----------------+-----+\n","|         England| 1719|\n","+----------------+-----+\n","\n"]}],"source":["## Test task 2.3 get_most_popular_nationality(year)\n","for year in range(2015, 2023):\n","    get_most_popular_nationality(year)"]},{"cell_type":"markdown","id":"fbb511ce-0c89-4da6-a554-610d0888fed0","metadata":{},"source":["Task 3"]},{"cell_type":"code","execution_count":12,"id":"b913db3f-2b1d-4598-a838-00a069bc569f","metadata":{},"outputs":[],"source":["# data preprocession\n","from pyspark.ml import Pipeline,Transformer\n","from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","\n","# define all useful features\n","feature_cols_int = [\"weak_foot\", \"skill_moves\", \"international_reputation\", \"pace\", \"shooting\", \"passing\", \"dribbling\", \"defending\", \"physic\", \"attacking_crossing\", \"attacking_finishing\", \"attacking_heading_accuracy\", \"attacking_short_passing\", \"attacking_volleys\", \"skill_dribbling\", \"skill_curve\", \"skill_fk_accuracy\", \"skill_long_passing\", \"skill_ball_control\", \"movement_acceleration\", \"movement_sprint_speed\", \"movement_agility\", \"movement_reactions\", \"movement_balance\", \"power_shot_power\", \"power_jumping\", \"power_stamina\", \"power_strength\", \"power_long_shots\", \"mentality_aggression\", \"mentality_interceptions\", \"mentality_positioning\", \"mentality_vision\", \"mentality_penalties\", \"defending_marking_awareness\", \"defending_standing_tackle\", \"defending_sliding_tackle\", \"goalkeeping_diving\", \"goalkeeping_handling\", \"goalkeeping_kicking\", \"goalkeeping_positioning\", \"goalkeeping_reflexes\", \"goalkeeping_speed\"]\n","feature_cols_to_onehot = [\"work_rate\", \"mentality_composure\", \"ls\", \"st\", \"rs\", \"lw\", \"lf\", \"cf\", \"rf\", \"rw\", \"lam\", \"cam\", \"ram\", \"lm\", \"lcm\", \"cm\", \"rcm\", \"rm\", \"lwb\", \"ldm\", \"cdm\", \"rdm\", \"rwb\", \"lb\", \"lcb\", \"cb\", \"rcb\", \"rb\", \"gk\"]\n","outcome_col = [\"overall\"]\n","df = df_read.select(feature_cols_int + feature_cols_to_onehot + outcome_col)"]},{"cell_type":"code","execution_count":13,"id":"b6944cf2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["-RECORD 0-----------------------------------------\n"," weak_foot                   | 0.0                \n"," skill_moves                 | 0.0                \n"," international_reputation    | 0.0                \n"," pace                        | 11.114239261256062 \n"," shooting                    | 11.114239261256062 \n"," passing                     | 11.114239261256062 \n"," dribbling                   | 11.114239261256062 \n"," defending                   | 11.114239261256062 \n"," physic                      | 11.114239261256062 \n"," attacking_crossing          | 0.0                \n"," attacking_finishing         | 0.0                \n"," attacking_heading_accuracy  | 0.0                \n"," attacking_short_passing     | 0.0                \n"," attacking_volleys           | 0.0                \n"," skill_dribbling             | 0.0                \n"," skill_curve                 | 0.0                \n"," skill_fk_accuracy           | 0.0                \n"," skill_long_passing          | 0.0                \n"," skill_ball_control          | 0.0                \n"," movement_acceleration       | 0.0                \n"," movement_sprint_speed       | 0.0                \n"," movement_agility            | 0.0                \n"," movement_reactions          | 0.0                \n"," movement_balance            | 0.0                \n"," power_shot_power            | 0.0                \n"," power_jumping               | 0.0                \n"," power_stamina               | 0.0                \n"," power_strength              | 0.0                \n"," power_long_shots            | 0.0                \n"," mentality_aggression        | 0.0                \n"," mentality_interceptions     | 0.0                \n"," mentality_positioning       | 0.0                \n"," mentality_vision            | 0.0                \n"," mentality_penalties         | 0.0                \n"," defending_marking_awareness | 0.0                \n"," defending_standing_tackle   | 0.0                \n"," defending_sliding_tackle    | 0.0                \n"," goalkeeping_diving          | 0.0                \n"," goalkeeping_handling        | 0.0                \n"," goalkeeping_kicking         | 0.0                \n"," goalkeeping_positioning     | 0.0                \n"," goalkeeping_reflexes        | 0.0                \n"," goalkeeping_speed           | 88.88576073874394  \n"," work_rate                   | 0.0                \n"," mentality_composure         | 22.366429943904446 \n"," ls                          | 0.0                \n"," st                          | 0.0                \n"," rs                          | 0.0                \n"," lw                          | 0.0                \n"," lf                          | 0.0                \n"," cf                          | 0.0                \n"," rf                          | 0.0                \n"," rw                          | 0.0                \n"," lam                         | 0.0                \n"," cam                         | 0.0                \n"," ram                         | 0.0                \n"," lm                          | 0.0                \n"," lcm                         | 0.0                \n"," cm                          | 0.0                \n"," rcm                         | 0.0                \n"," rm                          | 0.0                \n"," lwb                         | 0.0                \n"," ldm                         | 0.0                \n"," cdm                         | 0.0                \n"," rdm                         | 0.0                \n"," rwb                         | 0.0                \n"," lb                          | 0.0                \n"," lcb                         | 0.0                \n"," cb                          | 0.0                \n"," rcb                         | 0.0                \n"," rb                          | 0.0                \n"," gk                          | 0.0                \n"," overall                     | 0.0                \n","\n"]}],"source":["# calculate the ratio of null value for each feature\n","df_count = df.count()\n","null_counts_df = df.select([(count(when(isnan(col(c)) | col(c).isNull(), c))/df_count*100).alias(c) \\\n","                        for c in df.columns])\n","null_counts_df.show(vertical=True)"]},{"cell_type":"code","execution_count":14,"id":"46c07f4e","metadata":{},"outputs":[],"source":["# drop \"goalkeeping_speed\" because tremendous missing values, then drop the rest data if there is missing value in each row\n","df = df.drop(\"goalkeeping_speed\")\n","feature_cols_int.remove(\"goalkeeping_speed\")\n","df = df.dropna()"]},{"cell_type":"code","execution_count":15,"id":"7975c078","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# encode all features and generate final df\n","for c in (feature_cols_int + outcome_col):\n","    df = df.withColumn(c+\"_encoded\", col(c).cast(DoubleType()))\n","feature_cols_int_to_double = [x+\"_encoded\" for x in (feature_cols_int + outcome_col)]\n","feature_cols_index = [x+\"_index\" for x in feature_cols_to_onehot]\n","feature_cols_onehot = [x+\"_encoded\" for x in feature_cols_to_onehot]\n","indexer = StringIndexer(inputCols=feature_cols_to_onehot, outputCols=feature_cols_index, handleInvalid=\"keep\")\n","df_index_encoded = indexer.fit(df).transform(df)\n","encoder = OneHotEncoder(inputCols=feature_cols_index, outputCols=feature_cols_onehot, handleInvalid=\"keep\")\n","df_onehot_encoded = encoder.fit(df_index_encoded).transform(df_index_encoded)\n","assembler = VectorAssembler(inputCols=feature_cols_int_to_double + feature_cols_onehot, outputCol=\"features\", handleInvalid=\"keep\")\n","df_assembled = assembler.transform(df_onehot_encoded)\n","df_final = df_assembled.select([\"features\", \"overall_encoded\"])"]},{"cell_type":"code","execution_count":16,"id":"151340be","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 82:=======================================>                (14 + 6) / 20]\r"]},{"name":"stdout","output_type":"stream","text":["-RECORD 0-------------------------------\n"," features        | (7993,[0,1,2,3,4,... \n"," overall_encoded | 94.0                 \n","-RECORD 1-------------------------------\n"," features        | (7993,[0,1,2,3,4,... \n"," overall_encoded | 93.0                 \n","-RECORD 2-------------------------------\n"," features        | (7993,[0,1,2,3,4,... \n"," overall_encoded | 92.0                 \n","-RECORD 3-------------------------------\n"," features        | (7993,[0,1,2,3,4,... \n"," overall_encoded | 92.0                 \n","-RECORD 4-------------------------------\n"," features        | (7993,[0,1,2,3,4,... \n"," overall_encoded | 90.0                 \n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 82:============================================>           (16 + 4) / 20]\r","\r","                                                                                \r"]}],"source":["# example cases of df_final\n","df_final.show(5, vertical=True)"]},{"cell_type":"code","execution_count":17,"id":"c1e14c11","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 83:====================================================>   (27 + 2) / 29]\r"]},{"name":"stdout","output_type":"stream","text":["there are 50 distinct labels\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# there are only 50 different labels, so that the problem can be regarded as classification problem\n","N_labels = df_final.select(\"overall_encoded\").distinct().count()\n","print(f\"there are {N_labels} distinct labels\")"]},{"cell_type":"code","execution_count":18,"id":"0381ec17","metadata":{},"outputs":[],"source":["# Only randomly choose 2000 rows as the dataset for further training and testing to save time\n","df_omit = df_final.sample(withReplacement=False, fraction=1.0).limit(10000)\n","train_data, test_data = df_omit.randomSplit([0.8, 0.2])"]},{"cell_type":"code","execution_count":19,"id":"b92e6d28","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/11/13 03:25:56 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:26:05 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:26:11 WARN DAGScheduler: Broadcasting large task binary with size 1248.7 KiB\n","24/11/13 03:26:16 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:18 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:19 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:20 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:21 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:22 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:23 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:24 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:25 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:25 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:26 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:27 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:29 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:30 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:32 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:33 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:35 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:36 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:38 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:39 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:40 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:42 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:43 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:44 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:45 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:47 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:48 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:49 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:50 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:52 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:53 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:54 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:55 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:57 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:58 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:26:59 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:00 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:02 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:03 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:04 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:05 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:07 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:08 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:09 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:10 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:10 ERROR TransportClient: Failed to send RPC RPC 7184526175781629879 to /10.128.0.11:42884: io.netty.channel.StacklessClosedChannelException\n","io.netty.channel.StacklessClosedChannelException: null\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","24/11/13 03:27:10 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 252 from block manager BlockManagerId(3, cluster-542b-w-0.us-central1-f.c.white-option-435019-n2.internal, 45885, None)\n","java.io.IOException: Failed to send RPC RPC 7184526175781629879 to /10.128.0.11:42884: io.netty.channel.StacklessClosedChannelException\n","\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:395) ~[spark-network-common_2.12-3.5.1.jar:3.5.1]\n","\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:372) ~[spark-network-common_2.12-3.5.1.jar:3.5.1]\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:629) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:118) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:877) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:940) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1247) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat java.base/java.lang.Thread.run(Thread.java:829) [?:?]\n","Caused by: io.netty.channel.StacklessClosedChannelException\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","24/11/13 03:27:10 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /10.128.0.10:41194 is closed\n","24/11/13 03:27:10 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 252 from block manager BlockManagerId(2, cluster-542b-w-1.us-central1-f.c.white-option-435019-n2.internal, 35913, None)\n","java.io.IOException: Connection from /10.128.0.10:41194 closed\n","\tat org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:147) ~[spark-network-common_2.12-3.5.1.jar:3.5.1]\n","\tat org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117) ~[spark-network-common_2.12-3.5.1.jar:3.5.1]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:305) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277) ~[netty-handler-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:303) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225) ~[spark-network-common_2.12-3.5.1.jar:3.5.1]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:305) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:301) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:813) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:566) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n","\tat java.base/java.lang.Thread.run(Thread.java:829) [?:?]\n"]},{"name":"stderr","output_type":"stream","text":["24/11/13 03:27:12 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:13 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:14 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:16 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:17 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:18 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:18 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n","24/11/13 03:27:22 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:27:36 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:27:50 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n","[Stage 200:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["the logistic regression with regParam=0.01 and maxIter=50 achieves accuracy:12.890625%\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Logistic Regression on spark\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","lr = LogisticRegression(featuresCol=\"features\", labelCol=\"overall_encoded\", regParam=0.01, maxIter=50)\n","lr_model = lr.fit(train_data)\n","predictions = lr_model.transform(test_data)\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"the logistic regression with regParam=0.01 and maxIter=50 achieves accuracy:{100*accuracy}%\")"]},{"cell_type":"code","execution_count":20,"id":"57f8c0a6","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/11/13 03:28:02 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:28:09 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:28:15 WARN DAGScheduler: Broadcasting large task binary with size 1246.2 KiB\n","24/11/13 03:28:17 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:28:23 WARN DAGScheduler: Broadcasting large task binary with size 1247.2 KiB\n","24/11/13 03:28:23 WARN DAGScheduler: Broadcasting large task binary with size 1247.3 KiB\n","24/11/13 03:28:24 WARN DAGScheduler: Broadcasting large task binary with size 1250.9 KiB\n","24/11/13 03:28:27 WARN DAGScheduler: Broadcasting large task binary with size 1554.9 KiB\n","24/11/13 03:28:36 WARN DAGScheduler: Broadcasting large task binary with size 1557.8 KiB\n","24/11/13 03:28:44 WARN DAGScheduler: Broadcasting large task binary with size 1562.7 KiB\n","24/11/13 03:28:52 WARN DAGScheduler: Broadcasting large task binary with size 1572.6 KiB\n","24/11/13 03:28:59 WARN DAGScheduler: Broadcasting large task binary with size 1584.9 KiB\n","24/11/13 03:29:04 WARN DAGScheduler: Broadcasting large task binary with size 1604.4 KiB\n","24/11/13 03:29:09 WARN DAGScheduler: Broadcasting large task binary with size 1633.8 KiB\n","24/11/13 03:29:15 WARN DAGScheduler: Broadcasting large task binary with size 1685.4 KiB\n","24/11/13 03:29:22 WARN DAGScheduler: Broadcasting large task binary with size 1765.8 KiB\n","24/11/13 03:29:29 WARN DAGScheduler: Broadcasting large task binary with size 1858.2 KiB\n","24/11/13 03:29:34 WARN DAGScheduler: Broadcasting large task binary with size 1950.5 KiB\n","24/11/13 03:29:38 WARN DAGScheduler: Broadcasting large task binary with size 2042.6 KiB\n","24/11/13 03:29:43 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n","24/11/13 03:29:47 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n","24/11/13 03:29:51 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n","24/11/13 03:29:55 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/11/13 03:29:59 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/11/13 03:30:03 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n","24/11/13 03:30:07 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n","24/11/13 03:30:12 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n","24/11/13 03:30:17 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n","24/11/13 03:30:21 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n","24/11/13 03:30:27 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n","24/11/13 03:30:32 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n","24/11/13 03:30:36 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n","24/11/13 03:30:39 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n","24/11/13 03:30:42 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n","24/11/13 03:30:45 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n","24/11/13 03:30:48 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n","24/11/13 03:30:50 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n","24/11/13 03:30:52 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n","24/11/13 03:30:54 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n","24/11/13 03:30:56 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n","24/11/13 03:30:57 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n","24/11/13 03:30:59 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n","24/11/13 03:31:01 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n","24/11/13 03:31:02 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n","24/11/13 03:31:03 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n","24/11/13 03:31:04 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n","24/11/13 03:31:07 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:31:14 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n","[Stage 333:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["when impurity=entropy, maxDepth=30, there is highest accuracy for Decision Tree: 23.4375%\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Decision Classifier on Spark\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"overall_encoded\", maxDepth=30, impurity=\"entropy\")\n","dt_model = dt.fit(train_data)\n","predictions = dt_model.transform(test_data)\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"when impurity=entropy, maxDepth=30, there is highest accuracy for Decision Tree: {100*accuracy}%\")"]},{"cell_type":"code","execution_count":21,"id":"7e3432ac","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/11/13 03:31:31 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:31:39 WARN DAGScheduler: Broadcasting large task binary with size 1230.6 KiB\n","24/11/13 03:31:42 WARN DAGScheduler: Broadcasting large task binary with size 1293.6 KiB\n","24/11/13 03:31:49 WARN DAGScheduler: Broadcasting large task binary with size 1230.6 KiB\n","                                                                                \r"]}],"source":["# transform data from spark to tensor\n","import torch \n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","train_data_pd = train_data.toPandas()\n","test_data_pd = test_data.toPandas()\n","X_train = torch.Tensor(train_data_pd[\"features\"])\n","y_train = torch.Tensor(train_data_pd[\"overall_encoded\"])\n","X_test = torch.Tensor(test_data_pd[\"features\"])\n","y_test = torch.Tensor(test_data_pd[\"overall_encoded\"])"]},{"cell_type":"code","execution_count":22,"id":"6b376868","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# pytorch neural network 1 without hidden layer\n","import torch \n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","N_labels = df_final.select(\"overall_encoded\").distinct().count()\n","class MyDataset(Dataset):\n","    def __init__(self,x,y):\n","        self.x = x\n","        self.y = y\n","    def __len__(self):\n","        return self.x.shape[0]\n","    def __getitem__(self, idx):\n","        return (self.x[idx],self.y[idx])\n","\n","train_dataset = MyDataset(X_train, y_train)\n","test_dataset = MyDataset(X_test, y_test)\n","\n","class myModel1(nn.Module):\n","    def __init__(self, input_dims, output_dims):\n","        super().__init__()\n","        self.seq = nn.Sequential(\n","            nn.Linear(input_dims, output_dims),\n","        )\n","    def forward(self, X):\n","            return self.seq(X)"]},{"cell_type":"code","execution_count":23,"id":"e223d3d4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["myModel1(\n","  (seq): Sequential(\n","    (0): Linear(in_features=7993, out_features=1, bias=True)\n","  )\n",")\n"]}],"source":["# model1 structure\n","model = myModel1(train_dataset.x.shape[1], 1)\n","print(model)"]},{"cell_type":"code","execution_count":26,"id":"0d209fe8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["when lr=0.1, batch_size=500, there is highest accuracy for Model1: 22.94921875%\n"]}],"source":["lr=0.1\n","batch_size=500\n","N_epochs = 50\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle =True)\n","model = myModel1(train_dataset.x.shape[1], 1)\n","optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n","loss_fn = nn.MSELoss()\n","for epoch in range(N_epochs):\n","    for batch_id, (x_batch, y_batch) in enumerate(train_dataloader):\n","        predictions = model(x_batch)\n","        loss = loss_fn(predictions, y_batch.reshape(-1, 1))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","pred = model(X_test)\n","accuracy = 100 * torch.sum(torch.round(pred) == y_test.reshape(-1, 1)) / len(y_test)\n","\n","print(f\"when lr=0.1, batch_size=500, there is highest accuracy for Model1: {accuracy}%\")"]},{"cell_type":"code","execution_count":27,"id":"565c58b4","metadata":{},"outputs":[],"source":["# pytorch neural network 2 with 3 hidden layers, each layer with 128 neurons\n","class myModel2(nn.Module):\n","    def __init__(self, input_dims, output_dims):\n","        super().__init__()\n","        self.seq = nn.Sequential(\n","            nn.Linear(input_dims, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, output_dims)\n","            \n","        )\n","    def forward(self, X):\n","            return self.seq(X)"]},{"cell_type":"code","execution_count":28,"id":"35de0546","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["myModel2(\n","  (seq): Sequential(\n","    (0): Linear(in_features=7993, out_features=128, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=128, out_features=128, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=128, out_features=128, bias=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=128, out_features=1, bias=True)\n","  )\n",")\n"]}],"source":["# model2 structure\n","model = myModel2(train_dataset.x.shape[1], 1)\n","print(model)"]},{"cell_type":"code","execution_count":29,"id":"a0f39bc3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["when lr=0.005, batch_size=500, there is highest accuracy: 24.0234375%\n"]}],"source":["lr=0.005\n","batch_size=500\n","N_epochs = 50\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle =True)\n","model = myModel2(train_dataset.x.shape[1], 1)\n","optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n","loss_fn = nn.MSELoss()\n","for epoch in range(N_epochs):\n","    for batch_id, (x_batch, y_batch) in enumerate(train_dataloader):\n","        predictions = model(x_batch)\n","        loss = loss_fn(predictions, y_batch.reshape(-1, 1))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","pred = model(X_test)\n","accuracy = 100 * torch.sum(torch.round(pred) == y_test.reshape(-1, 1)) / len(y_test)\n","\n","\n","print(f\"when lr=0.005, batch_size=500, there is highest accuracy: {accuracy}%\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}